---
title: AI学习笔记3
date: 2024-12-31 00:02:01
categories: AI
tags:
  - AI
  - 技术
---

# AI学习笔记3

##机器学习项目的7个主要阶段

机器学习（ML）项目通常可以分为**7个主要阶段**。每个阶段都有其特定的目标和任务。以下是详细的阶段划分及其解释：

####1. 问题定义（Problem Definition）

- **目标：**明确业务问题，定义项目目标。

- **关键任务：**与利益相关者沟通，了解业务需求，定义需要解决的问题类型（如分类、回归、聚类）。

- **输出：**明确的项目目标和评估指标。


####2. 数据收集（Data Collection）

- **目标：**收集解决问题所需的数据。

- **关键任务：**
  - 从内部或外部数据源中获取数据。
  - 如果数据不够，可以考虑使用公开数据集或进行数据扩充。
- **输出：**数据集的初步版本。


####3. **数据准备（Data Preparation）**

- **目标：**清理和组织数据，使其适合用于模型训练。

- **关键任务：**
  - **数据预处理（Data Pre-processing）：**包括数据清洗、去除重复值、处理缺失值。
  - **数据转换：**如归一化、标准化、类别编码。
  - **数据拆分：**将数据集划分为训练集、验证集和测试集。
- **输出：**清洗后的数据集。


####4. 探索性数据分析（Exploratory Data Analysis, EDA）

- **目标：**深入理解数据的分布、关系及其特征，以便发现潜在模式。

- **关键任务：**
  - **数据可视化：**使用图表（直方图、散点图、箱线图等）来理解数据分布。
  - **相关分析：**通过相关矩阵、统计量等方法来发现特征之间的关系。
  - **异常值检测：**识别和处理数据中的异常值。
- **输出：**数据的深入理解，为下一步特征工程提供基础。


####5. 特征工程（Feature Engineering）

- **目标：**创建、选择、转换特征，以提高模型的性能。

- **关键任务：**
  - **特征选择：**选择对目标变量最有影响的特征。
  - **特征创建：**通过组合现有特征或基于业务理解创建新特征。
  - **降维：**使用PCA等方法减少特征数量以降低模型复杂度。
- **输出：**优化后的特征集。


####6. 模型开发与评估（Model Development & Evaluation）

- **目标：**构建、训练和优化机器学习模型。

- **关键任务：**
  - **模型训练：**使用训练集来训练模型。
  - **超参数调优：**调整模型的超参数以提高性能。
  - **模型评估：**使用验证集和测试集评估模型的性能（如准确率、召回率、F1分数等）。
- **输出：**性能最佳的模型版本。


####7. 模型部署与监控（Model Deployment & Monitoring）

- **目标：**将模型部署到生产环境并监控其性能。

- **关键任务：**
  - **模型部署：**将模型集成到生产应用中。
  - **性能监控：**监控模型的预测性能、处理时间，确保其在真实环境中表现良好。
  - **模型维护：**根据需求进行模型更新和再训练。
- **输出：**已部署的模型及其维护计划。


####总结

机器学习项目的完整流程可以总结为以下**7个阶段**：

1. **问题定义**

2. **数据收集**

3. **数据准备**

4. **探索性数据分析**

5. **特征工程**

6. **模型开发与评估**

7. **模型部署与监控**

这个流程帮助团队有条不紊地构建高效的机器学习系统，从而更好地解决业务问题。



## 适合训练模型的 EC2 实例类型

####1. Amazon EC2 Trn 系列 (Trn1)

- **用途：**Trn 系列实例专为 高效能机器学习训练 任务而设计，配备了 AWS Trainium 处理器，这是专门为训练大规模 AI 模型（如大型语言模型）优化的硬件。Trn 实例提供 高效能与低能耗 的训练计算能力，能够显著减少环境影响。

- **适用场景：**大型语言模型（LLM）的训练、深度学习模型的训练，尤其适用于需要大量计算资源且关心能效的任务。

- **环境影响：**由于 Trainium 处理器的高效能与低能耗，Trn 系列对环境的影响最小，适合需要节能的训练任务。


####2. Amazon EC2 P 系列 (P4, P3)

- **用途：**P 系列实例专为 深度学习模型的训练 和 推理 优化，特别适合 GPU 密集型任务。P 系列配备 NVIDIA A100（P4）或 V100（P3）GPU，能够提供极高的计算能力。

- **适用场景：**训练大规模神经网络、图像处理、视频分析、自然语言处理（NLP）等。

- **环境影响：**虽然 P 系列非常强大，但它们消耗的能源相对较多，因此在能效方面不如 Trn 系列。


####3. Amazon EC2 G 系列 (G5)

- **用途：**G 系列实例特别适合 GPU 加速的机器学习推理和图形处理 工作负载。它们配备了 NVIDIA A10G Tensor Core GPU，虽然主要用于推理，但也可用于训练模型。

- **适用场景：**机器学习推理、图形密集型应用、机器学习模型的快速原型开发。

- **环境影响：**G 系列实例在推理时更高效，但用于训练大型模型时的能效可能不如 Trn 系列。


####4. Amazon EC2 C 系列 (C6i, C5n)

- **用途：**C 系列实例是 计算优化型实例，适用于高性能计算（HPC）任务。它们主要用于 CPU 密集型工作负载，但也能为不依赖 GPU 的某些 ML训练任务提供高效性能。

- **适用场景：**适合需要强大计算能力但不依赖于 GPU 的 ML 训练任务。

- **环境影响：**相比于 GPU 密集型实例，C 系列实例的能效较高，适合较轻量的训练工作负载。


####5. Amazon EC2 Inf 系列 (Inf1)

- **用途：**Inf 系列实例使用 AWS Inferentia 处理器，专门为 机器学习推理任务优化。它们虽然主要用于推理，但也适用于一些 AI 模型的训练。

- **适用场景：**机器学习推理、快速部署 ML 模型，特别适用于 推理优化 的场景。

- **环境影响：**Inferentia 处理器在推理时比传统的 GPU 更能效，减少了能耗，并且比其他实例类型对环境的影响小。


####6. Amazon EC2 M 系列 (M6g, M5)

- **用途：**M 系列是 通用型实例，适用于各种计算工作负载。虽然不如 P 系列或 G 系列那样专门优化 GPU 计算，但对于 不太依赖 GPU 的 ML 训练任务也能提供足够的计算能力。

- **适用场景：**适合中等规模的机器学习任务、需要平衡计算和内存的工作负载。

- **环境影响：**M 系列实例适用于一般的机器学习工作负载，能效较高，尤其是在没有 GPU 加速需求的情况下。


####总结：

- **Trn 系列：**最适合训练大型模型，特别是对能效要求高的任务。

- **P 系列：**适合 GPU 密集型的深度学习训练，性能强大但能效较低。

- **G 系列：**适合机器学习推理和图形处理，性能优越但训练效率不如 Trn 系列。

- **C 系列：**适合 CPU 密集型任务，能效较高，适合轻量级训练任务。

- **Inf 系列：**适用于机器学习推理，能效高，适合对能效要求高的任务。

- **M 系列：**适合多种工作负载，适合一般规模的机器学习训练任务。


因此，**Trn 系列** 是能效最优的选择，特别适合需要节能的大型 AI 模型训练任务。但根据任务需求，其他实例系列也可以提供不同程度的支持。



## Token

####1. Token 的基本概念

在自然语言处理（NLP）中，**Token** 是语言数据的最小处理单位。它是文本被 **分词（tokenization）** 后形成的一个个单位。Token 的定义取决于所采用的分词策略，可以是：

- **单词（Word）：**例如，"cat" 或 "apple" 这样的单词。

- **子词（Subword）：**例如，单词 "unhappiness" 可能被分为 "un" 和 "happiness" 这两个子词，或者更细粒度地分成 "un", "happi", "ness" 等多个部分。

- **字符（Character）：**有些模型会将文本拆分成单个字符作为 Token，如 "a", "b", "c"。


####2. Token 的作用

生成式 AI 模型（例如 GPT 系列、BERT 等）会将输入文本转化为 Token，然后基于这些 Token 来进行训练、推理和生成输出。具体步骤如下：

- **输入文本处理：**文本首先被转化为 Token，作为模型的输入。

- **模型处理：**模型会学习 Token 之间的关系和语义，在此基础上生成或预测新的 Token（例如生成句子、回答问题等）。

- **输出生成：**模型输出的 Token 会被重新组合为可读的文本。


####3. Token 的表示方式

每个 Token 通常会被转化为一个 **数字向量**（通过词嵌入或嵌入层）。这个向量在高维空间中表示该 Token 的语义信息，模型通过对这些向量进行操作来

捕捉语言中的语法和语义关系。

例如：

- "cat" -> [0.1, 0.3, 0.7]

- "dog" -> [0.2, 0.4, 0.8]


这些向量不是直接的数字，而是根据预训练嵌入模型（例如 Word2Vec、GloVe 或 GPT 中的嵌入层）学习到的向量空间。

####4. Tokenization

**Tokenization（分词）** 是将文本分解为 Token 的过程。不同的模型和任务使用不同的分词策略：

- **Word-level tokenization（单词级分词）：**每个 Token 代表一个完整的单词。适用于简单的任务，但无法处理拼接或变形单词（例如复数、时态变化等）。

- **Subword-level tokenization（子词级分词）：**例如 BPE（Byte Pair Encoding）或 SentencePiece，这种方法通过拆分单词为子单元（如词根、词缀）来处理不常见的单词或词汇外的单词。

- **Character-level tokenization（字符级分词）：**每个 Token 是一个字符，这种方法适用于一些语言模型（如字符级 LSTM 模型）。


####5. Token 的大小和影响

Token 的 **数量** 影响着生成式 AI 模型的性能：

- **短文本：**例如简单句子、标题，通常包含较少的 Tokens。

- **长文本：**例如段落、文章，通常包含更多的 Tokens，这对模型的计算和存储提出挑战。


生成式 AI 模型通常对 Token 的数量有一个限制（如 GPT 模型的最大 Token 长度为 2048 或 4096），超过这个限制的文本需要被截断或分段处理。

####6. 在生成式 AI 中的应用

- **文本生成：**例如 GPT 模型通过预测一个接一个的 Token 来生成连贯的文本。每生成一个 Token，就会根据先前生成的 Token 预测下一个最可能的 Token。

- **机器翻译：**在翻译过程中，Token 是从源语言到目标语言的映射单位。

- **文本摘要：**生成摘要时，模型会从输入的文本中提取出有意义的 Token，并生成一个简洁的摘要。


####7. 如何理解和使用 Token

在实际应用中，开发者或研究人员可以利用 Token 来控制模型的生成行为。通过修改输入的 Token 顺序、选择特定的 Token，可以影响输出文本的内容和风格。例如：

- **使用不同的 Token 顺序：**可能会改变生成的文本结构。

- **调整 Token 的生成策略：**通过改变概率分布来控制生成文本的创意性、重复性等。


####总结

- **Token** 是生成式 AI 模型操作的基本单位，它可以是单词、子词或字符，取决于模型的分词策略。

- 模型通过将文本拆解为 Token，并处理这些 Token 来理解和生成语言。

- Token 是模型输入和输出的核心组成部分，对文本生成、机器翻译、摘要等任务起到决定性作用。